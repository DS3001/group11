{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Lab #2\n",
    "## Foundations of Machine Learning\n",
    "\n",
    "The purpose of this project is to build predictive algorithms that predict the likelihood a person has a stroke. The data include:\n",
    "  \n",
    "  - `age`: Patient age, numeric\n",
    "  - `avg_glucose_level`: Blood sugar levels, numeric\n",
    "  - `bmi`: Body mass index, numeric\n",
    "  - `ever_married`: Ever married, dummy/character (Yes, No)\n",
    "  - `gender`: Male, Female, or Other, character\n",
    "  - `heart_disease`: Has heart disease, dummy\n",
    "  - `hypertension`: Has hypertension, dummy\n",
    "  - `id`: Study identification number\n",
    "  - `Residence_type`: Type of residence, dummy/character (Urban, Rural)\n",
    "  - `smoking_status`: Former, never, or current smoker, categorical\n",
    "  - `work_type`: Employment type (Never worked (Never_worked), homemaker (\"children\"), Public sector employment (Govt_job), Private sector employment (`Private`), Self-employed (`Self-employed`)\n",
    "  - `stroke`: Suffered a stroke in the sample period\n",
    "  \n",
    "The data come in two files: `training_data.csv`, which you should use to build your models, and `testing_data.csv`, which you should use to test your models. The models must be trained on the training data and tested on the testing data, but providing both files allows you to experiment with your choices and iterate on model designs. If performance drops on the testing data, you know there's a problem.\n",
    "  \n",
    "You can use any of the tools presented in class: $k$ nearest neighbor, linear models, or decision trees. In principle, $k$ means clustering might also be helpful for looking for patterns in the data that the other methods might miss. Using canned versions of more advanced tools (boosting, bagging, random forests, neural networks, etc.) is deeply unsporting and thus not allowed. You can be creative about transforming variables, or combining decision trees with linear models or $k$NN. Try something interesting. Fail extravagantly. The goal is to work on an intellectually interesting question that is similar to the tasks that data scientists are called on to do every day.\n",
    "  \n",
    "We will compare the groups' models to see if there are common trends or significant differences, and also to declare **The Winners** on the basis of whichever team achieves the lowest $RMSE$ on the testing data. A simple linear model with some polynomials and dummy variables achieves an $R^2$ of .087 and a $RMSE$ of .206. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0        2465  68685    Male  36.0             0              0          Yes   \n",
      "1        4311  59058  Female  45.0             0              0          Yes   \n",
      "2        2375  46068    Male  58.0             0              0           No   \n",
      "3        5017  36837  Female  61.0             0              0          Yes   \n",
      "4         753  30550  Female  78.0             0              0           No   \n",
      "\n",
      "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0       Govt_job          Urban              65.87  32.2  formerly smoked   \n",
      "1       Govt_job          Rural              68.66  25.3     never smoked   \n",
      "2  Self-employed          Rural             170.93  30.7          Unknown   \n",
      "3  Self-employed          Urban              69.88  27.1     never smoked   \n",
      "4        Private          Urban             103.86  30.6          Unknown   \n",
      "\n",
      "   stroke  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('./data/training_data.csv')\n",
    "df_test = pd.read_csv('./data/testing_data.csv')\n",
    "print(df_train.head())\n",
    "gdf_test = pd.DataFrame.copy(df_test)\n",
    "gdf_train = pd.DataFrame.copy(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never smoked       1505\n",
      "Unknown            1241\n",
      "formerly smoked     699\n",
      "smokes              642\n",
      "Name: smoking_status, dtype: int64\n",
      "never smoked       387\n",
      "Unknown            303\n",
      "formerly smoked    186\n",
      "smokes             147\n",
      "Name: smoking_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "#for smoking status two options: remove nulls or make unkowns as a smoker\n",
    "#removing Unknown values for smoking\n",
    "var = 'smoking_status'\n",
    "print(df_train[var].value_counts()) #1241 unknown values for smoking status of train\n",
    "print(df_test[var].value_counts()) #303 unknown values for smoking status of test\n",
    "gdf_train[var] = gdf_train[var].replace('Unknown', np.nan)\n",
    "gdf_test[var] = gdf_test[var].replace('Unknown', np.nan)\n",
    "gdf_train[var+'_NA'] = gdf_train[var].isnull()\n",
    "gdf_test[var+'_NA'] = gdf_test[var].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick either one below and try to run in multiple ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke              0   1\n",
      "smoking_status           \n",
      "Unknown          1204  37\n",
      "formerly smoked   645  54\n",
      "never smoked     1434  71\n",
      "smokes            605  37 \n",
      "\n",
      "stroke             0   1\n",
      "smoking_status          \n",
      "Unknown          293  10\n",
      "formerly smoked  170  16\n",
      "never smoked     368  19\n",
      "smokes           142   5 \n",
      "\n",
      "work_type        Govt_job  Never_worked  Private  Self-employed  children\n",
      "smoking_status                                                           \n",
      "Unknown               100             7      518            129       487\n",
      "formerly smoked       108             0      419            161        11\n",
      "never smoked          229             8      955            271        42\n",
      "smokes                 97             0      437            106         2 \n",
      "\n",
      "age              0.16   0.24   0.32   0.48   0.56   0.64   0.72   0.88   \\\n",
      "smoking_status                                                            \n",
      "Unknown              1      1      1      1      1      1      2      1   \n",
      "formerly smoked      0      0      0      0      0      0      0      0   \n",
      "never smoked         0      0      0      0      0      0      0      0   \n",
      "smokes               0      0      0      0      0      0      0      0   \n",
      "\n",
      "age              1.00   1.08   ...  73.00  74.00  75.00  76.00  77.00  78.00  \\\n",
      "smoking_status                 ...                                             \n",
      "Unknown              2      1  ...      3      0      5      4      4      3   \n",
      "formerly smoked      0      0  ...      4      1      6      4      2      5   \n",
      "never smoked         0      0  ...      5      5      2      5      0      4   \n",
      "smokes               0      0  ...      2      1      2      1      0      1   \n",
      "\n",
      "age              79.00  80.00  81.00  82.00  \n",
      "smoking_status                               \n",
      "Unknown              4      3      2      2  \n",
      "formerly smoked      4      3      1      7  \n",
      "never smoked         6      8      4      6  \n",
      "smokes               2      2      0      0  \n",
      "\n",
      "[4 rows x 99 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(df_train[var],df_train['stroke']),'\\n') #cant assume anything with the stroke \n",
    "print(pd.crosstab(df_test[var],df_test['stroke']),'\\n') #cant assume anything with the stroke \n",
    "\n",
    "print(pd.crosstab(df_train[var],df_train['work_type']),'\\n') #cant assume anything with the stroke \n",
    "print(pd.crosstab(df_test[var],df_test['work_type']),'\\n') #cant assume anything with the stroke \n",
    "\n",
    "#print(pd.crosstab(gdf_test[var+'_NA'],gdf_test['stroke']),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pd.crosstab(df[var+'_NA'],df['satjob']),'\\n')\n",
    "#gdf_test[var].hist(bins=20,grid=False)\n",
    "df_train[var].hist(bins=20,grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Unknown values for smoking\n",
    "gdf_test=gdf_test.loc[gdf_test[var+'_NA']== 0,:]\n",
    "gdf_train=gdf_train.loc[gdf_train[var+'_NA']== 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missings: \n",
      " 0 \n",
      "\n",
      "Total Missings: \n",
      " 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#replacing unknown values as smoking as assume that people who did not awnser that question probably are smoking still\n",
    "gdf_train.loc[gdf_train[var].isnull(), var] = 'smokes' # Changing rows with nans to a new category called \"not happy\"\n",
    "print('Total Missings: \\n', sum(gdf_train[var].isnull()),'\\n') # checks that nulls were renamed\n",
    "gdf_test.loc[gdf_test[var].isnull(), var] = 'smokes' # Changing rows with nans to a new category called \"not happy\"\n",
    "print('Total Missings: \\n', sum(gdf_test[var].isnull()),'\\n') # checks that nulls were renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['stroke']\n",
    "X_train = df_train.drop('stroke',axis=1)\n",
    "y_test = df_test['stroke']\n",
    "X_test = df_test.drop('stroke',axis=1)\n",
    "\n",
    "X_train['bmi'] = X_train['bmi'].fillna(X_train['bmi'].mean())\n",
    "X_test['bmi'] = X_test['bmi'].fillna(X_test['bmi'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.08717964343843831\n",
      "RMSE:  0.20599583849613765\n"
     ]
    }
   ],
   "source": [
    "## Linear Model\n",
    "from sklearn.linear_model import LinearRegression # Import linear regression model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train_numeric = X_train.loc[:,['age','hypertension','heart_disease','bmi','avg_glucose_level'] ]\n",
    "#\n",
    "expander = PolynomialFeatures(degree=2,include_bias=False) # Create the expander\n",
    "Z = expander.fit_transform(X_train_numeric) # Pass the df into the expander to get powers/interactions of x and y\n",
    "names = expander.get_feature_names_out() # Get the names of these variables\n",
    "continuous = pd.DataFrame(data=Z, columns = names) # Create a new, expanded dataframe\n",
    "#\n",
    "dummies = pd.concat([ pd.get_dummies(X_train['work_type'],dtype='int',drop_first=True),\n",
    "                      pd.get_dummies(X_train['Residence_type'],dtype='int',drop_first=True),\n",
    "                      pd.get_dummies(X_train['smoking_status'],dtype='int',drop_first=True)],axis=1)\n",
    "#\n",
    "Z_train = pd.concat([continuous,dummies],axis=1)\n",
    "\n",
    "X_test_numeric = X_test.loc[:,['age','hypertension','heart_disease','bmi','avg_glucose_level'] ]\n",
    "#\n",
    "expander = PolynomialFeatures(degree=2,include_bias=False) # Create the expander\n",
    "Z = expander.fit_transform(X_test_numeric) # Pass the df into the expander to get powers/interactions of x and y\n",
    "names = expander.get_feature_names_out() # Get the names of these variables\n",
    "continuous = pd.DataFrame(data=Z, columns = names) # Create a new, expanded dataframe\n",
    "\n",
    "dummies = pd.concat([ pd.get_dummies(X_test['work_type'],dtype='int',drop_first=True),\n",
    "                      pd.get_dummies(X_test['Residence_type'],dtype='int',drop_first=True),\n",
    "                      pd.get_dummies(X_test['smoking_status'],dtype='int',drop_first=True)],axis=1)\n",
    "#\n",
    "Z_test = pd.concat([continuous,dummies],axis=1)\n",
    "\n",
    "# Fit the model and get the R2 measure:\n",
    "reg = LinearRegression().fit(Z_train, y_train) # Fit the linear model\n",
    "print('R2: ', reg.score(Z_test, y_test)) # R squared measure\n",
    "y_hat = reg.predict(Z_test)\n",
    "N = len(y_test)\n",
    "print('RMSE: ', (np.sum( (y_test - y_hat)**2)/N )**.5 )   # R squared measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is supposed to be fairly \"fun,\" so please do not turn it into a combinatorial nightmare of comparing thousands of model specifications. Settle on a strategy you think is promising, crank it out, and write up the results. Your time and energy are valuable, so learn to recognize when the marginal cost of another twenty minutes on a project exceeds the benefit in terms of improving the results and your grade.\n",
    "  \n",
    "## Paper format\n",
    "\n",
    "The format of the paper should be:\n",
    "\n",
    "  - Summary: A one paragraph description of the question, methods, and results (about 350 words).\n",
    "  - Data: One to two pages discussing the data and key variables, and any challenges in reading, cleaning, and preparing them for analysis.\n",
    "  - Results: Two to five pages providing visualizations, statistics, a discussion of your methodology, and a presentation of your main findings. \n",
    "  - Conclusion: One to two pages summarizing the project, defending it from criticism, and suggesting additional work that was outside the scope of the project.\n",
    "  - Appendix: If you have a significant number of additional plots or table that you feel are essential to the project, you can put any amount of extra content at the end and reference it from the body of the paper. \n",
    "\n",
    "## Submission\n",
    "\r\n",
    "Half of each student's grade is based on their commits to the repo. Each student is expected to do something specific that contributes to the overall project outcome. Since commits are recorded explicitly by Git/GitHub, this is observable. A student can contribute by cleaning data, creating visualizations,performing analytic analyses,  or writing about results, but everyone has to do something substantial. A student's work doesn't need to make it into the final report to be valuable and substantial, and fulfill the requirement to make a contribution to the project. \r\n",
    "\r\n",
    "The other half of each student's grade is based on the written report. Groups will work together on combining results and writing up findings in a Jupyter noteb,ok, using code chunks to execute Python commands and markdown chunks to structure the paper and provide exposition. The notebook should run on Colab or Rivana from beginning to end without any errors.\r\n",
    "\n",
    "mbers submit.\n",
    "\n",
    "## Criteria\n",
    "\n",
    "The project is graded based on four criteria:\n",
    "\n",
    "  - Project Concept: What is the strategy for building and testing the group's models? How did the group decide how to use the tools presented so far in class? How did the group compare the performance of the options considered, and settle on a final choice for submission?\n",
    "  - Wrangling, EDA, and Visualization: How are are missing values handled? For variables with large numbers of missing values, to what extent do the data and documentation provide an explanation for the missing data? If multiple data sources are used, how are the data merged? For the main variables in the analysis, are the relevant data summarized and visualized through a histogram or kernel density plot where appropriate? Are basic quantitative features of the data addressed and explained? How are outliers characterized and addressed? \n",
    "  - Analysis: What are the groups' main findings? Do the tables, plots, and statistics support the conclusions? Is the research strategy carried out correctly? If the research strategy succeeds, are the results interpreted correctly and appropriately? If the research strategy fails, is a useful discussion of the flaws of the data collection process or the research strategy discussed?\n",
    "  - Replication/Documentation: Is the code appropriately commented? Can the main results be replicated from the code and original data files? Are significant choices noted and explained?\n",
    "\n",
    "Each of the four criteria are equally weighted (25 points out of 100)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
